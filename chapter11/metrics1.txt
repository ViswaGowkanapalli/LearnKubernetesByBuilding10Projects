# HELP go_gc_duration_seconds A summary of the GC invocation durations.
# TYPE go_gc_duration_seconds summary
go_gc_duration_seconds{quantile="0"} 8.424e-06
go_gc_duration_seconds{quantile="0.25"} 1.4134e-05
go_gc_duration_seconds{quantile="0.5"} 1.537e-05
go_gc_duration_seconds{quantile="0.75"} 1.7334e-05
go_gc_duration_seconds{quantile="1"} 8.9449e-05
go_gc_duration_seconds_sum 0.001928653
go_gc_duration_seconds_count 111
# HELP go_goroutines Number of goroutines that currently exist.
# TYPE go_goroutines gauge
go_goroutines 213
# HELP go_info Information about the Go environment.
# TYPE go_info gauge
go_info{version="go1.13.1"} 1
# HELP go_memstats_alloc_bytes Number of bytes allocated and still in use.
# TYPE go_memstats_alloc_bytes gauge
go_memstats_alloc_bytes 1.05261768e+08
# HELP go_memstats_alloc_bytes_total Total number of bytes allocated, even if freed.
# TYPE go_memstats_alloc_bytes_total counter
go_memstats_alloc_bytes_total 8.576543168e+09
# HELP go_memstats_buck_hash_sys_bytes Number of bytes used by the profiling bucket hash table.
# TYPE go_memstats_buck_hash_sys_bytes gauge
go_memstats_buck_hash_sys_bytes 2.067855e+06
# HELP go_memstats_frees_total Total number of frees.
# TYPE go_memstats_frees_total counter
go_memstats_frees_total 5.4182839e+07
# HELP go_memstats_gc_cpu_fraction The fraction of this program's available CPU time used by the GC since the program started.
# TYPE go_memstats_gc_cpu_fraction gauge
go_memstats_gc_cpu_fraction 0.002096948059758433
# HELP go_memstats_gc_sys_bytes Number of bytes used for garbage collection system metadata.
# TYPE go_memstats_gc_sys_bytes gauge
go_memstats_gc_sys_bytes 1.0366976e+07
# HELP go_memstats_heap_alloc_bytes Number of heap bytes allocated and still in use.
# TYPE go_memstats_heap_alloc_bytes gauge
go_memstats_heap_alloc_bytes 1.05261768e+08
# HELP go_memstats_heap_idle_bytes Number of heap bytes waiting to be used.
# TYPE go_memstats_heap_idle_bytes gauge
go_memstats_heap_idle_bytes 1.43065088e+08
# HELP go_memstats_heap_inuse_bytes Number of heap bytes that are in use.
# TYPE go_memstats_heap_inuse_bytes gauge
go_memstats_heap_inuse_bytes 1.2353536e+08
# HELP go_memstats_heap_objects Number of allocated objects.
# TYPE go_memstats_heap_objects gauge
go_memstats_heap_objects 696135
# HELP go_memstats_heap_released_bytes Number of heap bytes released to OS.
# TYPE go_memstats_heap_released_bytes gauge
go_memstats_heap_released_bytes 5.1437568e+07
# HELP go_memstats_heap_sys_bytes Number of heap bytes obtained from system.
# TYPE go_memstats_heap_sys_bytes gauge
go_memstats_heap_sys_bytes 2.66600448e+08
# HELP go_memstats_last_gc_time_seconds Number of seconds since 1970 of last garbage collection.
# TYPE go_memstats_last_gc_time_seconds gauge
go_memstats_last_gc_time_seconds 1.5784927301218362e+09
# HELP go_memstats_lookups_total Total number of pointer lookups.
# TYPE go_memstats_lookups_total counter
go_memstats_lookups_total 0
# HELP go_memstats_mallocs_total Total number of mallocs.
# TYPE go_memstats_mallocs_total counter
go_memstats_mallocs_total 5.4878974e+07
# HELP go_memstats_mcache_inuse_bytes Number of bytes in use by mcache structures.
# TYPE go_memstats_mcache_inuse_bytes gauge
go_memstats_mcache_inuse_bytes 1736
# HELP go_memstats_mcache_sys_bytes Number of bytes used for mcache structures obtained from system.
# TYPE go_memstats_mcache_sys_bytes gauge
go_memstats_mcache_sys_bytes 16384
# HELP go_memstats_mspan_inuse_bytes Number of bytes in use by mspan structures.
# TYPE go_memstats_mspan_inuse_bytes gauge
go_memstats_mspan_inuse_bytes 2.009672e+06
# HELP go_memstats_mspan_sys_bytes Number of bytes used for mspan structures obtained from system.
# TYPE go_memstats_mspan_sys_bytes gauge
go_memstats_mspan_sys_bytes 2.736128e+06
# HELP go_memstats_next_gc_bytes Number of heap bytes when next garbage collection will take place.
# TYPE go_memstats_next_gc_bytes gauge
go_memstats_next_gc_bytes 2.01774544e+08
# HELP go_memstats_other_sys_bytes Number of bytes used for other system allocations.
# TYPE go_memstats_other_sys_bytes gauge
go_memstats_other_sys_bytes 965481
# HELP go_memstats_stack_inuse_bytes Number of bytes in use by the stack allocator.
# TYPE go_memstats_stack_inuse_bytes gauge
go_memstats_stack_inuse_bytes 1.835008e+06
# HELP go_memstats_stack_sys_bytes Number of bytes obtained from system for stack allocator.
# TYPE go_memstats_stack_sys_bytes gauge
go_memstats_stack_sys_bytes 1.835008e+06
# HELP go_memstats_sys_bytes Number of bytes obtained from system.
# TYPE go_memstats_sys_bytes gauge
go_memstats_sys_bytes 2.8458828e+08
# HELP go_threads Number of OS threads created.
# TYPE go_threads gauge
go_threads 8
# HELP net_conntrack_dialer_conn_attempted_total Total number of connections attempted by the given dialer a given name.
# TYPE net_conntrack_dialer_conn_attempted_total counter
net_conntrack_dialer_conn_attempted_total{dialer_name="alertmanager"} 1
net_conntrack_dialer_conn_attempted_total{dialer_name="default"} 0
net_conntrack_dialer_conn_attempted_total{dialer_name="monitor/prometheus-operator-alertmanager/0"} 1
net_conntrack_dialer_conn_attempted_total{dialer_name="monitor/prometheus-operator-apiserver/0"} 3
net_conntrack_dialer_conn_attempted_total{dialer_name="monitor/prometheus-operator-coredns/0"} 237
net_conntrack_dialer_conn_attempted_total{dialer_name="monitor/prometheus-operator-grafana/0"} 1
net_conntrack_dialer_conn_attempted_total{dialer_name="monitor/prometheus-operator-kube-controller-manager/0"} 0
net_conntrack_dialer_conn_attempted_total{dialer_name="monitor/prometheus-operator-kube-etcd/0"} 0
net_conntrack_dialer_conn_attempted_total{dialer_name="monitor/prometheus-operator-kube-proxy/0"} 0
net_conntrack_dialer_conn_attempted_total{dialer_name="monitor/prometheus-operator-kube-scheduler/0"} 0
net_conntrack_dialer_conn_attempted_total{dialer_name="monitor/prometheus-operator-kube-state-metrics/0"} 1
net_conntrack_dialer_conn_attempted_total{dialer_name="monitor/prometheus-operator-kubelet/0"} 3
net_conntrack_dialer_conn_attempted_total{dialer_name="monitor/prometheus-operator-kubelet/1"} 3
net_conntrack_dialer_conn_attempted_total{dialer_name="monitor/prometheus-operator-node-exporter/0"} 3
net_conntrack_dialer_conn_attempted_total{dialer_name="monitor/prometheus-operator-operator/0"} 1
net_conntrack_dialer_conn_attempted_total{dialer_name="monitor/prometheus-operator-prometheus/0"} 1
# HELP net_conntrack_dialer_conn_closed_total Total number of connections closed which originated from the dialer of a given name.
# TYPE net_conntrack_dialer_conn_closed_total counter
net_conntrack_dialer_conn_closed_total{dialer_name="alertmanager"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="default"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="monitor/prometheus-operator-alertmanager/0"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="monitor/prometheus-operator-apiserver/0"} 2
net_conntrack_dialer_conn_closed_total{dialer_name="monitor/prometheus-operator-coredns/0"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="monitor/prometheus-operator-grafana/0"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="monitor/prometheus-operator-kube-controller-manager/0"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="monitor/prometheus-operator-kube-etcd/0"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="monitor/prometheus-operator-kube-proxy/0"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="monitor/prometheus-operator-kube-scheduler/0"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="monitor/prometheus-operator-kube-state-metrics/0"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="monitor/prometheus-operator-kubelet/0"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="monitor/prometheus-operator-kubelet/1"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="monitor/prometheus-operator-node-exporter/0"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="monitor/prometheus-operator-operator/0"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="monitor/prometheus-operator-prometheus/0"} 0
# HELP net_conntrack_dialer_conn_established_total Total number of connections successfully established by the given dialer a given name.
# TYPE net_conntrack_dialer_conn_established_total counter
net_conntrack_dialer_conn_established_total{dialer_name="alertmanager"} 1
net_conntrack_dialer_conn_established_total{dialer_name="default"} 0
net_conntrack_dialer_conn_established_total{dialer_name="monitor/prometheus-operator-alertmanager/0"} 1
net_conntrack_dialer_conn_established_total{dialer_name="monitor/prometheus-operator-apiserver/0"} 3
net_conntrack_dialer_conn_established_total{dialer_name="monitor/prometheus-operator-coredns/0"} 0
net_conntrack_dialer_conn_established_total{dialer_name="monitor/prometheus-operator-grafana/0"} 1
net_conntrack_dialer_conn_established_total{dialer_name="monitor/prometheus-operator-kube-controller-manager/0"} 0
net_conntrack_dialer_conn_established_total{dialer_name="monitor/prometheus-operator-kube-etcd/0"} 0
net_conntrack_dialer_conn_established_total{dialer_name="monitor/prometheus-operator-kube-proxy/0"} 0
net_conntrack_dialer_conn_established_total{dialer_name="monitor/prometheus-operator-kube-scheduler/0"} 0
net_conntrack_dialer_conn_established_total{dialer_name="monitor/prometheus-operator-kube-state-metrics/0"} 1
net_conntrack_dialer_conn_established_total{dialer_name="monitor/prometheus-operator-kubelet/0"} 3
net_conntrack_dialer_conn_established_total{dialer_name="monitor/prometheus-operator-kubelet/1"} 3
net_conntrack_dialer_conn_established_total{dialer_name="monitor/prometheus-operator-node-exporter/0"} 3
net_conntrack_dialer_conn_established_total{dialer_name="monitor/prometheus-operator-operator/0"} 1
net_conntrack_dialer_conn_established_total{dialer_name="monitor/prometheus-operator-prometheus/0"} 1
# HELP net_conntrack_dialer_conn_failed_total Total number of connections failed to dial by the dialer a given name.
# TYPE net_conntrack_dialer_conn_failed_total counter
net_conntrack_dialer_conn_failed_total{dialer_name="alertmanager",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="alertmanager",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="alertmanager",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="alertmanager",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="default",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="default",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="default",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="default",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-alertmanager/0",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-alertmanager/0",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-alertmanager/0",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-alertmanager/0",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-apiserver/0",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-apiserver/0",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-apiserver/0",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-apiserver/0",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-coredns/0",reason="refused"} 237
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-coredns/0",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-coredns/0",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-coredns/0",reason="unknown"} 237
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-grafana/0",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-grafana/0",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-grafana/0",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-grafana/0",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-kube-controller-manager/0",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-kube-controller-manager/0",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-kube-controller-manager/0",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-kube-controller-manager/0",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-kube-etcd/0",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-kube-etcd/0",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-kube-etcd/0",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-kube-etcd/0",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-kube-proxy/0",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-kube-proxy/0",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-kube-proxy/0",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-kube-proxy/0",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-kube-scheduler/0",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-kube-scheduler/0",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-kube-scheduler/0",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-kube-scheduler/0",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-kube-state-metrics/0",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-kube-state-metrics/0",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-kube-state-metrics/0",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-kube-state-metrics/0",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-kubelet/0",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-kubelet/0",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-kubelet/0",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-kubelet/0",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-kubelet/1",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-kubelet/1",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-kubelet/1",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-kubelet/1",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-node-exporter/0",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-node-exporter/0",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-node-exporter/0",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-node-exporter/0",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-operator/0",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-operator/0",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-operator/0",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-operator/0",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-prometheus/0",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-prometheus/0",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-prometheus/0",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="monitor/prometheus-operator-prometheus/0",reason="unknown"} 0
# HELP net_conntrack_listener_conn_accepted_total Total number of connections opened to the listener of a given name.
# TYPE net_conntrack_listener_conn_accepted_total counter
net_conntrack_listener_conn_accepted_total{listener_name="http"} 1442
# HELP net_conntrack_listener_conn_closed_total Total number of connections closed that were made to the listener of a given name.
# TYPE net_conntrack_listener_conn_closed_total counter
net_conntrack_listener_conn_closed_total{listener_name="http"} 1438
# HELP process_cpu_seconds_total Total user and system CPU time spent in seconds.
# TYPE process_cpu_seconds_total counter
process_cpu_seconds_total 62.92
# HELP process_max_fds Maximum number of open file descriptors.
# TYPE process_max_fds gauge
process_max_fds 1.048576e+06
# HELP process_open_fds Number of open file descriptors.
# TYPE process_open_fds gauge
process_open_fds 29
# HELP process_resident_memory_bytes Resident memory size in bytes.
# TYPE process_resident_memory_bytes gauge
process_resident_memory_bytes 2.66940416e+08
# HELP process_start_time_seconds Start time of the process since unix epoch in seconds.
# TYPE process_start_time_seconds gauge
process_start_time_seconds 1.57848916309e+09
# HELP process_virtual_memory_bytes Virtual memory size in bytes.
# TYPE process_virtual_memory_bytes gauge
process_virtual_memory_bytes 3.77315328e+08
# HELP process_virtual_memory_max_bytes Maximum amount of virtual memory available in bytes.
# TYPE process_virtual_memory_max_bytes gauge
process_virtual_memory_max_bytes -1
# HELP prometheus_api_remote_read_queries The current number of remote read queries being executed or waiting.
# TYPE prometheus_api_remote_read_queries gauge
prometheus_api_remote_read_queries 0
# HELP prometheus_build_info A metric with a constant '1' value labeled by version, revision, branch, and goversion from which prometheus was built.
# TYPE prometheus_build_info gauge
prometheus_build_info{branch="HEAD",goversion="go1.13.1",revision="6f92ce56053866194ae5937012c1bec40f1dd1d9",version="2.13.1"} 1
# HELP prometheus_config_last_reload_success_timestamp_seconds Timestamp of the last successful configuration reload.
# TYPE prometheus_config_last_reload_success_timestamp_seconds gauge
prometheus_config_last_reload_success_timestamp_seconds 1.578489166347679e+09
# HELP prometheus_config_last_reload_successful Whether the last configuration reload attempt was successful.
# TYPE prometheus_config_last_reload_successful gauge
prometheus_config_last_reload_successful 1
# HELP prometheus_engine_queries The current number of queries being executed or waiting.
# TYPE prometheus_engine_queries gauge
prometheus_engine_queries 0
# HELP prometheus_engine_queries_concurrent_max The max number of concurrent queries.
# TYPE prometheus_engine_queries_concurrent_max gauge
prometheus_engine_queries_concurrent_max 20
# HELP prometheus_engine_query_duration_seconds Query timings
# TYPE prometheus_engine_query_duration_seconds summary
prometheus_engine_query_duration_seconds{slice="inner_eval",quantile="0.5"} 6.0796e-05
prometheus_engine_query_duration_seconds{slice="inner_eval",quantile="0.9"} 0.000704063
prometheus_engine_query_duration_seconds{slice="inner_eval",quantile="0.99"} 0.037426161
prometheus_engine_query_duration_seconds_sum{slice="inner_eval"} 24.278524235000113
prometheus_engine_query_duration_seconds_count{slice="inner_eval"} 16437
prometheus_engine_query_duration_seconds{slice="prepare_time",quantile="0.5"} 3.8314e-05
prometheus_engine_query_duration_seconds{slice="prepare_time",quantile="0.9"} 0.000224661
prometheus_engine_query_duration_seconds{slice="prepare_time",quantile="0.99"} 0.00842706
prometheus_engine_query_duration_seconds_sum{slice="prepare_time"} 4.578797998000002
prometheus_engine_query_duration_seconds_count{slice="prepare_time"} 16437
prometheus_engine_query_duration_seconds{slice="queue_time",quantile="0.5"} 8.21e-07
prometheus_engine_query_duration_seconds{slice="queue_time",quantile="0.9"} 1.852e-06
prometheus_engine_query_duration_seconds{slice="queue_time",quantile="0.99"} 8.613e-06
prometheus_engine_query_duration_seconds_sum{slice="queue_time"} 0.019357427999999993
prometheus_engine_query_duration_seconds_count{slice="queue_time"} 16437
prometheus_engine_query_duration_seconds{slice="result_sort",quantile="0.5"} NaN
prometheus_engine_query_duration_seconds{slice="result_sort",quantile="0.9"} NaN
prometheus_engine_query_duration_seconds{slice="result_sort",quantile="0.99"} NaN
prometheus_engine_query_duration_seconds_sum{slice="result_sort"} 0
prometheus_engine_query_duration_seconds_count{slice="result_sort"} 0
# HELP prometheus_http_request_duration_seconds Histogram of latencies for HTTP requests.
# TYPE prometheus_http_request_duration_seconds histogram
prometheus_http_request_duration_seconds_bucket{handler="/",le="0.1"} 2
prometheus_http_request_duration_seconds_bucket{handler="/",le="0.2"} 2
prometheus_http_request_duration_seconds_bucket{handler="/",le="0.4"} 2
prometheus_http_request_duration_seconds_bucket{handler="/",le="1"} 2
prometheus_http_request_duration_seconds_bucket{handler="/",le="3"} 2
prometheus_http_request_duration_seconds_bucket{handler="/",le="8"} 2
prometheus_http_request_duration_seconds_bucket{handler="/",le="20"} 2
prometheus_http_request_duration_seconds_bucket{handler="/",le="60"} 2
prometheus_http_request_duration_seconds_bucket{handler="/",le="120"} 2
prometheus_http_request_duration_seconds_bucket{handler="/",le="+Inf"} 2
prometheus_http_request_duration_seconds_sum{handler="/"} 6.6157e-05
prometheus_http_request_duration_seconds_count{handler="/"} 2
prometheus_http_request_duration_seconds_bucket{handler="/-/healthy",le="0.1"} 714
prometheus_http_request_duration_seconds_bucket{handler="/-/healthy",le="0.2"} 714
prometheus_http_request_duration_seconds_bucket{handler="/-/healthy",le="0.4"} 714
prometheus_http_request_duration_seconds_bucket{handler="/-/healthy",le="1"} 714
prometheus_http_request_duration_seconds_bucket{handler="/-/healthy",le="3"} 714
prometheus_http_request_duration_seconds_bucket{handler="/-/healthy",le="8"} 714
prometheus_http_request_duration_seconds_bucket{handler="/-/healthy",le="20"} 714
prometheus_http_request_duration_seconds_bucket{handler="/-/healthy",le="60"} 714
prometheus_http_request_duration_seconds_bucket{handler="/-/healthy",le="120"} 714
prometheus_http_request_duration_seconds_bucket{handler="/-/healthy",le="+Inf"} 714
prometheus_http_request_duration_seconds_sum{handler="/-/healthy"} 0.009334339000000007
prometheus_http_request_duration_seconds_count{handler="/-/healthy"} 714
prometheus_http_request_duration_seconds_bucket{handler="/-/ready",le="0.1"} 715
prometheus_http_request_duration_seconds_bucket{handler="/-/ready",le="0.2"} 715
prometheus_http_request_duration_seconds_bucket{handler="/-/ready",le="0.4"} 715
prometheus_http_request_duration_seconds_bucket{handler="/-/ready",le="1"} 715
prometheus_http_request_duration_seconds_bucket{handler="/-/ready",le="3"} 715
prometheus_http_request_duration_seconds_bucket{handler="/-/ready",le="8"} 715
prometheus_http_request_duration_seconds_bucket{handler="/-/ready",le="20"} 715
prometheus_http_request_duration_seconds_bucket{handler="/-/ready",le="60"} 715
prometheus_http_request_duration_seconds_bucket{handler="/-/ready",le="120"} 715
prometheus_http_request_duration_seconds_bucket{handler="/-/ready",le="+Inf"} 715
prometheus_http_request_duration_seconds_sum{handler="/-/ready"} 0.009293088000000017
prometheus_http_request_duration_seconds_count{handler="/-/ready"} 715
prometheus_http_request_duration_seconds_bucket{handler="/-/reload",le="0.1"} 1
prometheus_http_request_duration_seconds_bucket{handler="/-/reload",le="0.2"} 1
prometheus_http_request_duration_seconds_bucket{handler="/-/reload",le="0.4"} 1
prometheus_http_request_duration_seconds_bucket{handler="/-/reload",le="1"} 1
prometheus_http_request_duration_seconds_bucket{handler="/-/reload",le="3"} 1
prometheus_http_request_duration_seconds_bucket{handler="/-/reload",le="8"} 1
prometheus_http_request_duration_seconds_bucket{handler="/-/reload",le="20"} 1
prometheus_http_request_duration_seconds_bucket{handler="/-/reload",le="60"} 1
prometheus_http_request_duration_seconds_bucket{handler="/-/reload",le="120"} 1
prometheus_http_request_duration_seconds_bucket{handler="/-/reload",le="+Inf"} 1
prometheus_http_request_duration_seconds_sum{handler="/-/reload"} 0.064249979
prometheus_http_request_duration_seconds_count{handler="/-/reload"} 1
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/label/:name/values",le="0.1"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/label/:name/values",le="0.2"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/label/:name/values",le="0.4"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/label/:name/values",le="1"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/label/:name/values",le="3"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/label/:name/values",le="8"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/label/:name/values",le="20"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/label/:name/values",le="60"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/label/:name/values",le="120"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/label/:name/values",le="+Inf"} 2
prometheus_http_request_duration_seconds_sum{handler="/api/v1/label/:name/values"} 0.006181314
prometheus_http_request_duration_seconds_count{handler="/api/v1/label/:name/values"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query",le="0.1"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query",le="0.2"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query",le="0.4"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query",le="1"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query",le="3"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query",le="8"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query",le="20"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query",le="60"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query",le="120"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query",le="+Inf"} 2
prometheus_http_request_duration_seconds_sum{handler="/api/v1/query"} 0.002317572
prometheus_http_request_duration_seconds_count{handler="/api/v1/query"} 2
prometheus_http_request_duration_seconds_bucket{handler="/graph",le="0.1"} 2
prometheus_http_request_duration_seconds_bucket{handler="/graph",le="0.2"} 2
prometheus_http_request_duration_seconds_bucket{handler="/graph",le="0.4"} 2
prometheus_http_request_duration_seconds_bucket{handler="/graph",le="1"} 2
prometheus_http_request_duration_seconds_bucket{handler="/graph",le="3"} 2
prometheus_http_request_duration_seconds_bucket{handler="/graph",le="8"} 2
prometheus_http_request_duration_seconds_bucket{handler="/graph",le="20"} 2
prometheus_http_request_duration_seconds_bucket{handler="/graph",le="60"} 2
prometheus_http_request_duration_seconds_bucket{handler="/graph",le="120"} 2
prometheus_http_request_duration_seconds_bucket{handler="/graph",le="+Inf"} 2
prometheus_http_request_duration_seconds_sum{handler="/graph"} 0.00358749
prometheus_http_request_duration_seconds_count{handler="/graph"} 2
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="0.1"} 126
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="0.2"} 126
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="0.4"} 126
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="1"} 126
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="3"} 126
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="8"} 126
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="20"} 126
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="60"} 126
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="120"} 126
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="+Inf"} 126
prometheus_http_request_duration_seconds_sum{handler="/metrics"} 0.758684855
prometheus_http_request_duration_seconds_count{handler="/metrics"} 126
prometheus_http_request_duration_seconds_bucket{handler="/static/*filepath",le="0.1"} 24
prometheus_http_request_duration_seconds_bucket{handler="/static/*filepath",le="0.2"} 24
prometheus_http_request_duration_seconds_bucket{handler="/static/*filepath",le="0.4"} 24
prometheus_http_request_duration_seconds_bucket{handler="/static/*filepath",le="1"} 24
prometheus_http_request_duration_seconds_bucket{handler="/static/*filepath",le="3"} 24
prometheus_http_request_duration_seconds_bucket{handler="/static/*filepath",le="8"} 24
prometheus_http_request_duration_seconds_bucket{handler="/static/*filepath",le="20"} 24
prometheus_http_request_duration_seconds_bucket{handler="/static/*filepath",le="60"} 24
prometheus_http_request_duration_seconds_bucket{handler="/static/*filepath",le="120"} 24
prometheus_http_request_duration_seconds_bucket{handler="/static/*filepath",le="+Inf"} 24
prometheus_http_request_duration_seconds_sum{handler="/static/*filepath"} 0.012664646000000002
prometheus_http_request_duration_seconds_count{handler="/static/*filepath"} 24
# HELP prometheus_http_requests_total Counter of HTTP requests.
# TYPE prometheus_http_requests_total counter
prometheus_http_requests_total{code="200",handler="/-/healthy"} 714
prometheus_http_requests_total{code="200",handler="/-/ready"} 715
prometheus_http_requests_total{code="200",handler="/-/reload"} 1
prometheus_http_requests_total{code="200",handler="/api/v1/label/:name/values"} 2
prometheus_http_requests_total{code="200",handler="/api/v1/query"} 2
prometheus_http_requests_total{code="200",handler="/graph"} 2
prometheus_http_requests_total{code="200",handler="/metrics"} 126
prometheus_http_requests_total{code="200",handler="/static/*filepath"} 24
prometheus_http_requests_total{code="302",handler="/"} 2
# HELP prometheus_http_response_size_bytes Histogram of response size for HTTP requests.
# TYPE prometheus_http_response_size_bytes histogram
prometheus_http_response_size_bytes_bucket{handler="/",le="100"} 2
prometheus_http_response_size_bytes_bucket{handler="/",le="1000"} 2
prometheus_http_response_size_bytes_bucket{handler="/",le="10000"} 2
prometheus_http_response_size_bytes_bucket{handler="/",le="100000"} 2
prometheus_http_response_size_bytes_bucket{handler="/",le="1e+06"} 2
prometheus_http_response_size_bytes_bucket{handler="/",le="1e+07"} 2
prometheus_http_response_size_bytes_bucket{handler="/",le="1e+08"} 2
prometheus_http_response_size_bytes_bucket{handler="/",le="1e+09"} 2
prometheus_http_response_size_bytes_bucket{handler="/",le="+Inf"} 2
prometheus_http_response_size_bytes_sum{handler="/"} 58
prometheus_http_response_size_bytes_count{handler="/"} 2
prometheus_http_response_size_bytes_bucket{handler="/-/healthy",le="100"} 714
prometheus_http_response_size_bytes_bucket{handler="/-/healthy",le="1000"} 714
prometheus_http_response_size_bytes_bucket{handler="/-/healthy",le="10000"} 714
prometheus_http_response_size_bytes_bucket{handler="/-/healthy",le="100000"} 714
prometheus_http_response_size_bytes_bucket{handler="/-/healthy",le="1e+06"} 714
prometheus_http_response_size_bytes_bucket{handler="/-/healthy",le="1e+07"} 714
prometheus_http_response_size_bytes_bucket{handler="/-/healthy",le="1e+08"} 714
prometheus_http_response_size_bytes_bucket{handler="/-/healthy",le="1e+09"} 714
prometheus_http_response_size_bytes_bucket{handler="/-/healthy",le="+Inf"} 714
prometheus_http_response_size_bytes_sum{handler="/-/healthy"} 16422
prometheus_http_response_size_bytes_count{handler="/-/healthy"} 714
prometheus_http_response_size_bytes_bucket{handler="/-/ready",le="100"} 715
prometheus_http_response_size_bytes_bucket{handler="/-/ready",le="1000"} 715
prometheus_http_response_size_bytes_bucket{handler="/-/ready",le="10000"} 715
prometheus_http_response_size_bytes_bucket{handler="/-/ready",le="100000"} 715
prometheus_http_response_size_bytes_bucket{handler="/-/ready",le="1e+06"} 715
prometheus_http_response_size_bytes_bucket{handler="/-/ready",le="1e+07"} 715
prometheus_http_response_size_bytes_bucket{handler="/-/ready",le="1e+08"} 715
prometheus_http_response_size_bytes_bucket{handler="/-/ready",le="1e+09"} 715
prometheus_http_response_size_bytes_bucket{handler="/-/ready",le="+Inf"} 715
prometheus_http_response_size_bytes_sum{handler="/-/ready"} 15015
prometheus_http_response_size_bytes_count{handler="/-/ready"} 715
prometheus_http_response_size_bytes_bucket{handler="/-/reload",le="100"} 1
prometheus_http_response_size_bytes_bucket{handler="/-/reload",le="1000"} 1
prometheus_http_response_size_bytes_bucket{handler="/-/reload",le="10000"} 1
prometheus_http_response_size_bytes_bucket{handler="/-/reload",le="100000"} 1
prometheus_http_response_size_bytes_bucket{handler="/-/reload",le="1e+06"} 1
prometheus_http_response_size_bytes_bucket{handler="/-/reload",le="1e+07"} 1
prometheus_http_response_size_bytes_bucket{handler="/-/reload",le="1e+08"} 1
prometheus_http_response_size_bytes_bucket{handler="/-/reload",le="1e+09"} 1
prometheus_http_response_size_bytes_bucket{handler="/-/reload",le="+Inf"} 1
prometheus_http_response_size_bytes_sum{handler="/-/reload"} 0
prometheus_http_response_size_bytes_count{handler="/-/reload"} 1
prometheus_http_response_size_bytes_bucket{handler="/api/v1/label/:name/values",le="100"} 0
prometheus_http_response_size_bytes_bucket{handler="/api/v1/label/:name/values",le="1000"} 0
prometheus_http_response_size_bytes_bucket{handler="/api/v1/label/:name/values",le="10000"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/label/:name/values",le="100000"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/label/:name/values",le="1e+06"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/label/:name/values",le="1e+07"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/label/:name/values",le="1e+08"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/label/:name/values",le="1e+09"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/label/:name/values",le="+Inf"} 2
prometheus_http_response_size_bytes_sum{handler="/api/v1/label/:name/values"} 12328
prometheus_http_response_size_bytes_count{handler="/api/v1/label/:name/values"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query",le="100"} 0
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query",le="1000"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query",le="10000"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query",le="100000"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query",le="1e+06"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query",le="1e+07"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query",le="1e+08"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query",le="1e+09"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query",le="+Inf"} 2
prometheus_http_response_size_bytes_sum{handler="/api/v1/query"} 208
prometheus_http_response_size_bytes_count{handler="/api/v1/query"} 2
prometheus_http_response_size_bytes_bucket{handler="/graph",le="100"} 0
prometheus_http_response_size_bytes_bucket{handler="/graph",le="1000"} 0
prometheus_http_response_size_bytes_bucket{handler="/graph",le="10000"} 2
prometheus_http_response_size_bytes_bucket{handler="/graph",le="100000"} 2
prometheus_http_response_size_bytes_bucket{handler="/graph",le="1e+06"} 2
prometheus_http_response_size_bytes_bucket{handler="/graph",le="1e+07"} 2
prometheus_http_response_size_bytes_bucket{handler="/graph",le="1e+08"} 2
prometheus_http_response_size_bytes_bucket{handler="/graph",le="1e+09"} 2
prometheus_http_response_size_bytes_bucket{handler="/graph",le="+Inf"} 2
prometheus_http_response_size_bytes_sum{handler="/graph"} 11570
prometheus_http_response_size_bytes_count{handler="/graph"} 2
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="100"} 0
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="1000"} 0
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="10000"} 2
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="100000"} 126
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="1e+06"} 126
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="1e+07"} 126
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="1e+08"} 126
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="1e+09"} 126
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="+Inf"} 126
prometheus_http_response_size_bytes_sum{handler="/metrics"} 1.300704e+06
prometheus_http_response_size_bytes_count{handler="/metrics"} 126
prometheus_http_response_size_bytes_bucket{handler="/static/*filepath",le="100"} 0
prometheus_http_response_size_bytes_bucket{handler="/static/*filepath",le="1000"} 2
prometheus_http_response_size_bytes_bucket{handler="/static/*filepath",le="10000"} 9
prometheus_http_response_size_bytes_bucket{handler="/static/*filepath",le="100000"} 21
prometheus_http_response_size_bytes_bucket{handler="/static/*filepath",le="1e+06"} 24
prometheus_http_response_size_bytes_bucket{handler="/static/*filepath",le="1e+07"} 24
prometheus_http_response_size_bytes_bucket{handler="/static/*filepath",le="1e+08"} 24
prometheus_http_response_size_bytes_bucket{handler="/static/*filepath",le="1e+09"} 24
prometheus_http_response_size_bytes_bucket{handler="/static/*filepath",le="+Inf"} 24
prometheus_http_response_size_bytes_sum{handler="/static/*filepath"} 983113
prometheus_http_response_size_bytes_count{handler="/static/*filepath"} 24
# HELP prometheus_notifications_alertmanagers_discovered The number of alertmanagers discovered and active.
# TYPE prometheus_notifications_alertmanagers_discovered gauge
prometheus_notifications_alertmanagers_discovered 1
# HELP prometheus_notifications_dropped_total Total number of alerts dropped due to errors when sending to Alertmanager.
# TYPE prometheus_notifications_dropped_total counter
prometheus_notifications_dropped_total 0
# HELP prometheus_notifications_errors_total Total number of errors sending alert notifications.
# TYPE prometheus_notifications_errors_total counter
prometheus_notifications_errors_total{alertmanager="http://10.32.0.16:9093/api/v1/alerts"} 0
# HELP prometheus_notifications_latency_seconds Latency quantiles for sending alert notifications.
# TYPE prometheus_notifications_latency_seconds summary
prometheus_notifications_latency_seconds{alertmanager="http://10.32.0.16:9093/api/v1/alerts",quantile="0.5"} 0.001147515
prometheus_notifications_latency_seconds{alertmanager="http://10.32.0.16:9093/api/v1/alerts",quantile="0.9"} 0.00237872
prometheus_notifications_latency_seconds{alertmanager="http://10.32.0.16:9093/api/v1/alerts",quantile="0.99"} 0.004013178
prometheus_notifications_latency_seconds_sum{alertmanager="http://10.32.0.16:9093/api/v1/alerts"} 0.24936692199999988
prometheus_notifications_latency_seconds_count{alertmanager="http://10.32.0.16:9093/api/v1/alerts"} 173
# HELP prometheus_notifications_queue_capacity The capacity of the alert notifications queue.
# TYPE prometheus_notifications_queue_capacity gauge
prometheus_notifications_queue_capacity 10000
# HELP prometheus_notifications_queue_length The number of alert notifications in the queue.
# TYPE prometheus_notifications_queue_length gauge
prometheus_notifications_queue_length 0
# HELP prometheus_notifications_sent_total Total number of alerts sent.
# TYPE prometheus_notifications_sent_total counter
prometheus_notifications_sent_total{alertmanager="http://10.32.0.16:9093/api/v1/alerts"} 220
# HELP prometheus_remote_storage_highest_timestamp_in_seconds Highest timestamp that has come into the remote storage via the Appender interface, in seconds since epoch.
# TYPE prometheus_remote_storage_highest_timestamp_in_seconds gauge
prometheus_remote_storage_highest_timestamp_in_seconds 1.578492735e+09
# HELP prometheus_remote_storage_samples_in_total Samples in to remote storage, compare to samples out for queue managers.
# TYPE prometheus_remote_storage_samples_in_total counter
prometheus_remote_storage_samples_in_total 3.793621e+06
# HELP prometheus_remote_storage_string_interner_zero_reference_releases_total The number of times release has been called for strings that are not interned.
# TYPE prometheus_remote_storage_string_interner_zero_reference_releases_total counter
prometheus_remote_storage_string_interner_zero_reference_releases_total 0
# HELP prometheus_rule_evaluation_duration_seconds The duration for a rule to execute.
# TYPE prometheus_rule_evaluation_duration_seconds summary
prometheus_rule_evaluation_duration_seconds{quantile="0.5"} 0.000266353
prometheus_rule_evaluation_duration_seconds{quantile="0.9"} 0.001428675
prometheus_rule_evaluation_duration_seconds{quantile="0.99"} 0.050236974
prometheus_rule_evaluation_duration_seconds_sum 33.1363331269999
prometheus_rule_evaluation_duration_seconds_count 16435
# HELP prometheus_rule_evaluation_failures_total The total number of rule evaluation failures.
# TYPE prometheus_rule_evaluation_failures_total counter
prometheus_rule_evaluation_failures_total 0
# HELP prometheus_rule_evaluations_total The total number of rule evaluations.
# TYPE prometheus_rule_evaluations_total counter
prometheus_rule_evaluations_total 16435
# HELP prometheus_rule_group_duration_seconds The duration of rule group evaluations.
# TYPE prometheus_rule_group_duration_seconds summary
prometheus_rule_group_duration_seconds{quantile="0.01"} 0.000260869
prometheus_rule_group_duration_seconds{quantile="0.05"} 0.000338919
prometheus_rule_group_duration_seconds{quantile="0.5"} 0.001217193
prometheus_rule_group_duration_seconds{quantile="0.9"} 0.032984593
prometheus_rule_group_duration_seconds{quantile="0.99"} 0.312800879
prometheus_rule_group_duration_seconds_sum 33.179030231000006
prometheus_rule_group_duration_seconds_count 2143
# HELP prometheus_rule_group_interval_seconds The interval of a rule group.
# TYPE prometheus_rule_group_interval_seconds gauge
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-alertmanager.rules.yaml;alertmanager.rules"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-etcd.yaml;etcd"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-general.rules.yaml;general.rules"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-k8s.rules.yaml;k8s.rules"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kube-apiserver.rules.yaml;kube-apiserver.rules"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kube-prometheus-node-alerting.rules.yaml;kube-prometheus-node-alerting.rules"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kube-prometheus-node-recording.rules.yaml;kube-prometheus-node-recording.rules"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kube-scheduler.rules.yaml;kube-scheduler.rules"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kubernetes-absent.yaml;kubernetes-absent"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kubernetes-apps.yaml;kubernetes-apps"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kubernetes-resources.yaml;kubernetes-resources"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kubernetes-storage.yaml;kubernetes-storage"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kubernetes-system.yaml;kubernetes-system"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-node-network.yaml;node-network"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-node-time.yaml;node-time"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-node.rules.yaml;node.rules"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-prometheus-operator.yaml;prometheus-operator"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-prometheus.rules.yaml;prometheus.rules"} 30
# HELP prometheus_rule_group_iterations_missed_total The total number of rule group evaluations missed due to slow rule group evaluation.
# TYPE prometheus_rule_group_iterations_missed_total counter
prometheus_rule_group_iterations_missed_total 1
# HELP prometheus_rule_group_iterations_total The total number of scheduled rule group evaluations, whether executed or missed.
# TYPE prometheus_rule_group_iterations_total counter
prometheus_rule_group_iterations_total 2143
# HELP prometheus_rule_group_last_duration_seconds The duration of the last rule group evaluation.
# TYPE prometheus_rule_group_last_duration_seconds gauge
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-alertmanager.rules.yaml;alertmanager.rules"} 0.000662538
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-etcd.yaml;etcd"} 0.001999322
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-general.rules.yaml;general.rules"} 0.000823974
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-k8s.rules.yaml;k8s.rules"} 0.007151501
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kube-apiserver.rules.yaml;kube-apiserver.rules"} 0.144627958
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kube-prometheus-node-alerting.rules.yaml;kube-prometheus-node-alerting.rules"} 0.000821769
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kube-prometheus-node-recording.rules.yaml;kube-prometheus-node-recording.rules"} 0.002713753
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kube-scheduler.rules.yaml;kube-scheduler.rules"} 0.001176185
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kubernetes-absent.yaml;kubernetes-absent"} 0.001217193
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kubernetes-apps.yaml;kubernetes-apps"} 0.003505216
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kubernetes-resources.yaml;kubernetes-resources"} 0.003010171
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kubernetes-storage.yaml;kubernetes-storage"} 0.000639613
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kubernetes-system.yaml;kubernetes-system"} 0.035566999
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-node-network.yaml;node-network"} 0.001210919
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-node-time.yaml;node-time"} 0.000260869
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-node.rules.yaml;node.rules"} 0.046128808
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-prometheus-operator.yaml;prometheus-operator"} 0.000474482
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-prometheus.rules.yaml;prometheus.rules"} 0.001174292
# HELP prometheus_rule_group_last_evaluation_timestamp_seconds The timestamp of the last rule group evaluation in seconds.
# TYPE prometheus_rule_group_last_evaluation_timestamp_seconds gauge
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-alertmanager.rules.yaml;alertmanager.rules"} 1.5784927087161567e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-etcd.yaml;etcd"} 1.5784927225611591e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-general.rules.yaml;general.rules"} 1.5784927328899255e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-k8s.rules.yaml;k8s.rules"} 1.5784927097508445e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kube-apiserver.rules.yaml;kube-apiserver.rules"} 1.5784927239666321e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kube-prometheus-node-alerting.rules.yaml;kube-prometheus-node-alerting.rules"} 1.5784927215283415e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kube-prometheus-node-recording.rules.yaml;kube-prometheus-node-recording.rules"} 1.5784927191875367e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kube-scheduler.rules.yaml;kube-scheduler.rules"} 1.5784927226001618e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kubernetes-absent.yaml;kubernetes-absent"} 1.5784927089245348e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kubernetes-apps.yaml;kubernetes-apps"} 1.57849273585205e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kubernetes-resources.yaml;kubernetes-resources"} 1.5784927123577209e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kubernetes-storage.yaml;kubernetes-storage"} 1.5784927339191914e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kubernetes-system.yaml;kubernetes-system"} 1.578492718855989e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-node-network.yaml;node-network"} 1.5784927101504693e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-node-time.yaml;node-time"} 1.5784927276272054e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-node.rules.yaml;node.rules"} 1.5784927299885993e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-prometheus-operator.yaml;prometheus-operator"} 1.5784927196452572e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-prometheus.rules.yaml;prometheus.rules"} 1.5784927322917867e+09
# HELP prometheus_rule_group_rules The number of rules.
# TYPE prometheus_rule_group_rules gauge
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-alertmanager.rules.yaml;alertmanager.rules"} 3
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-etcd.yaml;etcd"} 13
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-general.rules.yaml;general.rules"} 2
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-k8s.rules.yaml;k8s.rules"} 8
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kube-apiserver.rules.yaml;kube-apiserver.rules"} 3
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kube-prometheus-node-alerting.rules.yaml;kube-prometheus-node-alerting.rules"} 2
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kube-prometheus-node-recording.rules.yaml;kube-prometheus-node-recording.rules"} 7
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kube-scheduler.rules.yaml;kube-scheduler.rules"} 9
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kubernetes-absent.yaml;kubernetes-absent"} 9
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kubernetes-apps.yaml;kubernetes-apps"} 13
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kubernetes-resources.yaml;kubernetes-resources"} 6
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kubernetes-storage.yaml;kubernetes-storage"} 3
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-kubernetes-system.yaml;kubernetes-system"} 13
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-node-network.yaml;node-network"} 3
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-node-time.yaml;node-time"} 1
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-node.rules.yaml;node.rules"} 31
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-prometheus-operator.yaml;prometheus-operator"} 2
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-prometheus-operator-prometheus-rulefiles-0/monitor-prometheus-operator-prometheus.rules.yaml;prometheus.rules"} 10
# HELP prometheus_sd_consul_rpc_duration_seconds The duration of a Consul RPC call in seconds.
# TYPE prometheus_sd_consul_rpc_duration_seconds summary
prometheus_sd_consul_rpc_duration_seconds{call="service",endpoint="catalog",quantile="0.5"} NaN
prometheus_sd_consul_rpc_duration_seconds{call="service",endpoint="catalog",quantile="0.9"} NaN
prometheus_sd_consul_rpc_duration_seconds{call="service",endpoint="catalog",quantile="0.99"} NaN
prometheus_sd_consul_rpc_duration_seconds_sum{call="service",endpoint="catalog"} 0
prometheus_sd_consul_rpc_duration_seconds_count{call="service",endpoint="catalog"} 0
prometheus_sd_consul_rpc_duration_seconds{call="services",endpoint="catalog",quantile="0.5"} NaN
prometheus_sd_consul_rpc_duration_seconds{call="services",endpoint="catalog",quantile="0.9"} NaN
prometheus_sd_consul_rpc_duration_seconds{call="services",endpoint="catalog",quantile="0.99"} NaN
prometheus_sd_consul_rpc_duration_seconds_sum{call="services",endpoint="catalog"} 0
prometheus_sd_consul_rpc_duration_seconds_count{call="services",endpoint="catalog"} 0
# HELP prometheus_sd_consul_rpc_failures_total The number of Consul RPC call failures.
# TYPE prometheus_sd_consul_rpc_failures_total counter
prometheus_sd_consul_rpc_failures_total 0
# HELP prometheus_sd_discovered_targets Current number of discovered targets.
# TYPE prometheus_sd_discovered_targets gauge
prometheus_sd_discovered_targets{config="58d70ec6be805d47039a8dfddff44059",name="notify"} 16
prometheus_sd_discovered_targets{config="monitor/prometheus-operator-alertmanager/0",name="scrape"} 16
prometheus_sd_discovered_targets{config="monitor/prometheus-operator-apiserver/0",name="scrape"} 1
prometheus_sd_discovered_targets{config="monitor/prometheus-operator-coredns/0",name="scrape"} 38
prometheus_sd_discovered_targets{config="monitor/prometheus-operator-grafana/0",name="scrape"} 16
prometheus_sd_discovered_targets{config="monitor/prometheus-operator-kube-controller-manager/0",name="scrape"} 38
prometheus_sd_discovered_targets{config="monitor/prometheus-operator-kube-etcd/0",name="scrape"} 38
prometheus_sd_discovered_targets{config="monitor/prometheus-operator-kube-proxy/0",name="scrape"} 38
prometheus_sd_discovered_targets{config="monitor/prometheus-operator-kube-scheduler/0",name="scrape"} 38
prometheus_sd_discovered_targets{config="monitor/prometheus-operator-kube-state-metrics/0",name="scrape"} 16
prometheus_sd_discovered_targets{config="monitor/prometheus-operator-kubelet/0",name="scrape"} 38
prometheus_sd_discovered_targets{config="monitor/prometheus-operator-kubelet/1",name="scrape"} 38
prometheus_sd_discovered_targets{config="monitor/prometheus-operator-node-exporter/0",name="scrape"} 16
prometheus_sd_discovered_targets{config="monitor/prometheus-operator-operator/0",name="scrape"} 16
prometheus_sd_discovered_targets{config="monitor/prometheus-operator-prometheus/0",name="scrape"} 16
# HELP prometheus_sd_dns_lookup_failures_total The number of DNS-SD lookup failures.
# TYPE prometheus_sd_dns_lookup_failures_total counter
prometheus_sd_dns_lookup_failures_total 0
# HELP prometheus_sd_dns_lookups_total The number of DNS-SD lookups.
# TYPE prometheus_sd_dns_lookups_total counter
prometheus_sd_dns_lookups_total 0
# HELP prometheus_sd_failed_configs Current number of service discovery configurations that failed to load.
# TYPE prometheus_sd_failed_configs gauge
prometheus_sd_failed_configs{name="notify"} 0
prometheus_sd_failed_configs{name="scrape"} 0
# HELP prometheus_sd_file_read_errors_total The number of File-SD read errors.
# TYPE prometheus_sd_file_read_errors_total counter
prometheus_sd_file_read_errors_total 0
# HELP prometheus_sd_file_scan_duration_seconds The duration of the File-SD scan in seconds.
# TYPE prometheus_sd_file_scan_duration_seconds summary
prometheus_sd_file_scan_duration_seconds{quantile="0.5"} NaN
prometheus_sd_file_scan_duration_seconds{quantile="0.9"} NaN
prometheus_sd_file_scan_duration_seconds{quantile="0.99"} NaN
prometheus_sd_file_scan_duration_seconds_sum 0
prometheus_sd_file_scan_duration_seconds_count 0
# HELP prometheus_sd_kubernetes_cache_last_resource_version Last resource version from the Kubernetes API.
# TYPE prometheus_sd_kubernetes_cache_last_resource_version gauge
prometheus_sd_kubernetes_cache_last_resource_version 0
# HELP prometheus_sd_kubernetes_cache_list_duration_seconds Duration of a Kubernetes API call in seconds.
# TYPE prometheus_sd_kubernetes_cache_list_duration_seconds summary
prometheus_sd_kubernetes_cache_list_duration_seconds_sum 0
prometheus_sd_kubernetes_cache_list_duration_seconds_count 0
# HELP prometheus_sd_kubernetes_cache_list_items Count of items in a list from the Kubernetes API.
# TYPE prometheus_sd_kubernetes_cache_list_items summary
prometheus_sd_kubernetes_cache_list_items_sum 0
prometheus_sd_kubernetes_cache_list_items_count 0
# HELP prometheus_sd_kubernetes_cache_list_total Total number of list operations.
# TYPE prometheus_sd_kubernetes_cache_list_total counter
prometheus_sd_kubernetes_cache_list_total 0
# HELP prometheus_sd_kubernetes_cache_short_watches_total Total number of short watch operations.
# TYPE prometheus_sd_kubernetes_cache_short_watches_total counter
prometheus_sd_kubernetes_cache_short_watches_total 0
# HELP prometheus_sd_kubernetes_cache_watch_duration_seconds Duration of watches on the Kubernetes API.
# TYPE prometheus_sd_kubernetes_cache_watch_duration_seconds summary
prometheus_sd_kubernetes_cache_watch_duration_seconds_sum 0
prometheus_sd_kubernetes_cache_watch_duration_seconds_count 0
# HELP prometheus_sd_kubernetes_cache_watch_events Number of items in watches on the Kubernetes API.
# TYPE prometheus_sd_kubernetes_cache_watch_events summary
prometheus_sd_kubernetes_cache_watch_events_sum 0
prometheus_sd_kubernetes_cache_watch_events_count 0
# HELP prometheus_sd_kubernetes_cache_watches_total Total number of watch operations.
# TYPE prometheus_sd_kubernetes_cache_watches_total counter
prometheus_sd_kubernetes_cache_watches_total 0
# HELP prometheus_sd_kubernetes_events_total The number of Kubernetes events handled.
# TYPE prometheus_sd_kubernetes_events_total counter
prometheus_sd_kubernetes_events_total{event="add",role="endpoints"} 68
prometheus_sd_kubernetes_events_total{event="add",role="ingress"} 0
prometheus_sd_kubernetes_events_total{event="add",role="node"} 0
prometheus_sd_kubernetes_events_total{event="add",role="pod"} 0
prometheus_sd_kubernetes_events_total{event="add",role="service"} 58
prometheus_sd_kubernetes_events_total{event="delete",role="endpoints"} 2
prometheus_sd_kubernetes_events_total{event="delete",role="ingress"} 0
prometheus_sd_kubernetes_events_total{event="delete",role="node"} 0
prometheus_sd_kubernetes_events_total{event="delete",role="pod"} 0
prometheus_sd_kubernetes_events_total{event="delete",role="service"} 2
prometheus_sd_kubernetes_events_total{event="update",role="endpoints"} 8963
prometheus_sd_kubernetes_events_total{event="update",role="ingress"} 0
prometheus_sd_kubernetes_events_total{event="update",role="node"} 0
prometheus_sd_kubernetes_events_total{event="update",role="pod"} 0
prometheus_sd_kubernetes_events_total{event="update",role="service"} 172
# HELP prometheus_sd_kubernetes_http_request_duration_seconds Summary of latencies for HTTP requests to the Kubernetes API by endpoint.
# TYPE prometheus_sd_kubernetes_http_request_duration_seconds summary
prometheus_sd_kubernetes_http_request_duration_seconds_sum{endpoint="/%7Bprefix%7D"} 1.9459923420000003
prometheus_sd_kubernetes_http_request_duration_seconds_count{endpoint="/%7Bprefix%7D"} 48
# HELP prometheus_sd_kubernetes_http_request_total Total number of HTTP requests to the Kubernetes API by status code.
# TYPE prometheus_sd_kubernetes_http_request_total counter
prometheus_sd_kubernetes_http_request_total{status_code="200"} 198
# HELP prometheus_sd_kubernetes_workqueue_depth Current depth of the work queue.
# TYPE prometheus_sd_kubernetes_workqueue_depth gauge
prometheus_sd_kubernetes_workqueue_depth{queue_name="endpoints"} 0
# HELP prometheus_sd_kubernetes_workqueue_items_total Total number of items added to the work queue.
# TYPE prometheus_sd_kubernetes_workqueue_items_total counter
prometheus_sd_kubernetes_workqueue_items_total{queue_name="endpoints"} 9141
# HELP prometheus_sd_kubernetes_workqueue_latency_seconds How long an item stays in the work queue.
# TYPE prometheus_sd_kubernetes_workqueue_latency_seconds summary
prometheus_sd_kubernetes_workqueue_latency_seconds_sum{queue_name="endpoints"} 3.933389022000027e-06
prometheus_sd_kubernetes_workqueue_latency_seconds_count{queue_name="endpoints"} 9141
# HELP prometheus_sd_kubernetes_workqueue_longest_running_processor_seconds Duration of the longest running processor in the work queue.
# TYPE prometheus_sd_kubernetes_workqueue_longest_running_processor_seconds gauge
prometheus_sd_kubernetes_workqueue_longest_running_processor_seconds{queue_name="endpoints"} 0
# HELP prometheus_sd_kubernetes_workqueue_unfinished_work_seconds How long an item has remained unfinished in the work queue.
# TYPE prometheus_sd_kubernetes_workqueue_unfinished_work_seconds gauge
prometheus_sd_kubernetes_workqueue_unfinished_work_seconds{queue_name="endpoints"} 0
# HELP prometheus_sd_kubernetes_workqueue_work_duration_seconds How long processing an item from the work queue takes.
# TYPE prometheus_sd_kubernetes_workqueue_work_duration_seconds summary
prometheus_sd_kubernetes_workqueue_work_duration_seconds_sum{queue_name="endpoints"} 1.9553405299999972e-07
prometheus_sd_kubernetes_workqueue_work_duration_seconds_count{queue_name="endpoints"} 9141
# HELP prometheus_sd_received_updates_total Total number of update events received from the SD providers.
# TYPE prometheus_sd_received_updates_total counter
prometheus_sd_received_updates_total{name="notify"} 119
prometheus_sd_received_updates_total{name="scrape"} 9022
# HELP prometheus_sd_updates_total Total number of update events sent to the SD consumers.
# TYPE prometheus_sd_updates_total counter
prometheus_sd_updates_total{name="notify"} 11
prometheus_sd_updates_total{name="scrape"} 703
# HELP prometheus_target_interval_length_seconds Actual intervals between scrapes.
# TYPE prometheus_target_interval_length_seconds summary
prometheus_target_interval_length_seconds{interval="30s",quantile="0.01"} 29.994009727
prometheus_target_interval_length_seconds{interval="30s",quantile="0.05"} 29.999960354
prometheus_target_interval_length_seconds{interval="30s",quantile="0.5"} 30.000020269
prometheus_target_interval_length_seconds{interval="30s",quantile="0.9"} 30.000057758
prometheus_target_interval_length_seconds{interval="30s",quantile="0.99"} 30.005815245
prometheus_target_interval_length_seconds_sum{interval="30s"} 60120.04060809681
prometheus_target_interval_length_seconds_count{interval="30s"} 2004
# HELP prometheus_target_scrape_pool_reloads_failed_total Total number of failed scrape loop reloads.
# TYPE prometheus_target_scrape_pool_reloads_failed_total counter
prometheus_target_scrape_pool_reloads_failed_total 0
# HELP prometheus_target_scrape_pool_reloads_total Total number of scrape loop reloads.
# TYPE prometheus_target_scrape_pool_reloads_total counter
prometheus_target_scrape_pool_reloads_total 0
# HELP prometheus_target_scrape_pool_sync_total Total number of syncs that were executed on a scrape pool.
# TYPE prometheus_target_scrape_pool_sync_total counter
prometheus_target_scrape_pool_sync_total{scrape_job="monitor/prometheus-operator-alertmanager/0"} 703
prometheus_target_scrape_pool_sync_total{scrape_job="monitor/prometheus-operator-apiserver/0"} 703
prometheus_target_scrape_pool_sync_total{scrape_job="monitor/prometheus-operator-coredns/0"} 703
prometheus_target_scrape_pool_sync_total{scrape_job="monitor/prometheus-operator-grafana/0"} 703
prometheus_target_scrape_pool_sync_total{scrape_job="monitor/prometheus-operator-kube-controller-manager/0"} 703
prometheus_target_scrape_pool_sync_total{scrape_job="monitor/prometheus-operator-kube-etcd/0"} 703
prometheus_target_scrape_pool_sync_total{scrape_job="monitor/prometheus-operator-kube-proxy/0"} 703
prometheus_target_scrape_pool_sync_total{scrape_job="monitor/prometheus-operator-kube-scheduler/0"} 703
prometheus_target_scrape_pool_sync_total{scrape_job="monitor/prometheus-operator-kube-state-metrics/0"} 703
prometheus_target_scrape_pool_sync_total{scrape_job="monitor/prometheus-operator-kubelet/0"} 703
prometheus_target_scrape_pool_sync_total{scrape_job="monitor/prometheus-operator-kubelet/1"} 703
prometheus_target_scrape_pool_sync_total{scrape_job="monitor/prometheus-operator-node-exporter/0"} 703
prometheus_target_scrape_pool_sync_total{scrape_job="monitor/prometheus-operator-operator/0"} 703
prometheus_target_scrape_pool_sync_total{scrape_job="monitor/prometheus-operator-prometheus/0"} 703
# HELP prometheus_target_scrape_pools_failed_total Total number of scrape pool creations that failed.
# TYPE prometheus_target_scrape_pools_failed_total counter
prometheus_target_scrape_pools_failed_total 0
# HELP prometheus_target_scrape_pools_total Total number of scrape pool creation attempts.
# TYPE prometheus_target_scrape_pools_total counter
prometheus_target_scrape_pools_total 14
# HELP prometheus_target_scrapes_cache_flush_forced_total How many times a scrape cache was flushed due to getting big while scrapes are failing.
# TYPE prometheus_target_scrapes_cache_flush_forced_total counter
prometheus_target_scrapes_cache_flush_forced_total 0
# HELP prometheus_target_scrapes_exceeded_sample_limit_total Total number of scrapes that hit the sample limit and were rejected.
# TYPE prometheus_target_scrapes_exceeded_sample_limit_total counter
prometheus_target_scrapes_exceeded_sample_limit_total 0
# HELP prometheus_target_scrapes_sample_duplicate_timestamp_total Total number of samples rejected due to duplicate timestamps but different values
# TYPE prometheus_target_scrapes_sample_duplicate_timestamp_total counter
prometheus_target_scrapes_sample_duplicate_timestamp_total 0
# HELP prometheus_target_scrapes_sample_out_of_bounds_total Total number of samples rejected due to timestamp falling outside of the time bounds
# TYPE prometheus_target_scrapes_sample_out_of_bounds_total counter
prometheus_target_scrapes_sample_out_of_bounds_total 0
# HELP prometheus_target_scrapes_sample_out_of_order_total Total number of samples rejected due to not being out of the expected order
# TYPE prometheus_target_scrapes_sample_out_of_order_total counter
prometheus_target_scrapes_sample_out_of_order_total 0
# HELP prometheus_target_sync_length_seconds Actual interval to sync the scrape pool.
# TYPE prometheus_target_sync_length_seconds summary
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-alertmanager/0",quantile="0.01"} 0.000314851
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-alertmanager/0",quantile="0.05"} 0.000326169
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-alertmanager/0",quantile="0.5"} 0.000389832
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-alertmanager/0",quantile="0.9"} 0.000447398
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-alertmanager/0",quantile="0.99"} 0.000750533
prometheus_target_sync_length_seconds_sum{scrape_job="monitor/prometheus-operator-alertmanager/0"} 0.341152514
prometheus_target_sync_length_seconds_count{scrape_job="monitor/prometheus-operator-alertmanager/0"} 703
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-apiserver/0",quantile="0.01"} 4.2464e-05
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-apiserver/0",quantile="0.05"} 4.3297e-05
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-apiserver/0",quantile="0.5"} 5.6697e-05
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-apiserver/0",quantile="0.9"} 9.1219e-05
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-apiserver/0",quantile="0.99"} 0.000124459
prometheus_target_sync_length_seconds_sum{scrape_job="monitor/prometheus-operator-apiserver/0"} 0.089853091
prometheus_target_sync_length_seconds_count{scrape_job="monitor/prometheus-operator-apiserver/0"} 703
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-coredns/0",quantile="0.01"} 0.000568097
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-coredns/0",quantile="0.05"} 0.000576495
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-coredns/0",quantile="0.5"} 0.00065774
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-coredns/0",quantile="0.9"} 0.000747309
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-coredns/0",quantile="0.99"} 0.008103296
prometheus_target_sync_length_seconds_sum{scrape_job="monitor/prometheus-operator-coredns/0"} 0.6053720809999997
prometheus_target_sync_length_seconds_count{scrape_job="monitor/prometheus-operator-coredns/0"} 703
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-grafana/0",quantile="0.01"} 0.000313529
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-grafana/0",quantile="0.05"} 0.000324244
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-grafana/0",quantile="0.5"} 0.000387604
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-grafana/0",quantile="0.9"} 0.000451929
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-grafana/0",quantile="0.99"} 0.001438027
prometheus_target_sync_length_seconds_sum{scrape_job="monitor/prometheus-operator-grafana/0"} 0.33975407299999993
prometheus_target_sync_length_seconds_count{scrape_job="monitor/prometheus-operator-grafana/0"} 703
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-kube-controller-manager/0",quantile="0.01"} 0.000428232
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-kube-controller-manager/0",quantile="0.05"} 0.000434171
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-kube-controller-manager/0",quantile="0.5"} 0.000504637
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-kube-controller-manager/0",quantile="0.9"} 0.000552505
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-kube-controller-manager/0",quantile="0.99"} 0.001493431
prometheus_target_sync_length_seconds_sum{scrape_job="monitor/prometheus-operator-kube-controller-manager/0"} 0.4438046259999998
prometheus_target_sync_length_seconds_count{scrape_job="monitor/prometheus-operator-kube-controller-manager/0"} 703
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-kube-etcd/0",quantile="0.01"} 0.000421616
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-kube-etcd/0",quantile="0.05"} 0.00043499
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-kube-etcd/0",quantile="0.5"} 0.000506691
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-kube-etcd/0",quantile="0.9"} 0.00061789
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-kube-etcd/0",quantile="0.99"} 0.0024326
prometheus_target_sync_length_seconds_sum{scrape_job="monitor/prometheus-operator-kube-etcd/0"} 0.5017657969999999
prometheus_target_sync_length_seconds_count{scrape_job="monitor/prometheus-operator-kube-etcd/0"} 703
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-kube-proxy/0",quantile="0.01"} 0.000421643
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-kube-proxy/0",quantile="0.05"} 0.000437024
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-kube-proxy/0",quantile="0.5"} 0.000518331
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-kube-proxy/0",quantile="0.9"} 0.000588133
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-kube-proxy/0",quantile="0.99"} 0.00116784
prometheus_target_sync_length_seconds_sum{scrape_job="monitor/prometheus-operator-kube-proxy/0"} 0.49210058599999984
prometheus_target_sync_length_seconds_count{scrape_job="monitor/prometheus-operator-kube-proxy/0"} 703
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-kube-scheduler/0",quantile="0.01"} 0.000426613
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-kube-scheduler/0",quantile="0.05"} 0.000433957
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-kube-scheduler/0",quantile="0.5"} 0.00050973
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-kube-scheduler/0",quantile="0.9"} 0.000597243
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-kube-scheduler/0",quantile="0.99"} 0.006931408
prometheus_target_sync_length_seconds_sum{scrape_job="monitor/prometheus-operator-kube-scheduler/0"} 0.4709417820000003
prometheus_target_sync_length_seconds_count{scrape_job="monitor/prometheus-operator-kube-scheduler/0"} 703
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-kube-state-metrics/0",quantile="0.01"} 0.000318494
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-kube-state-metrics/0",quantile="0.05"} 0.000333845
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-kube-state-metrics/0",quantile="0.5"} 0.000392351
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-kube-state-metrics/0",quantile="0.9"} 0.000478158
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-kube-state-metrics/0",quantile="0.99"} 0.001185683
prometheus_target_sync_length_seconds_sum{scrape_job="monitor/prometheus-operator-kube-state-metrics/0"} 0.33228631100000017
prometheus_target_sync_length_seconds_count{scrape_job="monitor/prometheus-operator-kube-state-metrics/0"} 703
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-kubelet/0",quantile="0.01"} 0.000525413
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-kubelet/0",quantile="0.05"} 0.000540729
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-kubelet/0",quantile="0.5"} 0.000633188
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-kubelet/0",quantile="0.9"} 0.000708446
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-kubelet/0",quantile="0.99"} 0.006372106
prometheus_target_sync_length_seconds_sum{scrape_job="monitor/prometheus-operator-kubelet/0"} 0.5771908250000001
prometheus_target_sync_length_seconds_count{scrape_job="monitor/prometheus-operator-kubelet/0"} 703
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-kubelet/1",quantile="0.01"} 0.000530074
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-kubelet/1",quantile="0.05"} 0.000537854
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-kubelet/1",quantile="0.5"} 0.000621775
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-kubelet/1",quantile="0.9"} 0.000726149
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-kubelet/1",quantile="0.99"} 0.008128201
prometheus_target_sync_length_seconds_sum{scrape_job="monitor/prometheus-operator-kubelet/1"} 0.6440526299999996
prometheus_target_sync_length_seconds_count{scrape_job="monitor/prometheus-operator-kubelet/1"} 703
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-node-exporter/0",quantile="0.01"} 0.000454499
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-node-exporter/0",quantile="0.05"} 0.000466594
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-node-exporter/0",quantile="0.5"} 0.00054495
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-node-exporter/0",quantile="0.9"} 0.000630324
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-node-exporter/0",quantile="0.99"} 0.001693431
prometheus_target_sync_length_seconds_sum{scrape_job="monitor/prometheus-operator-node-exporter/0"} 0.47171324600000014
prometheus_target_sync_length_seconds_count{scrape_job="monitor/prometheus-operator-node-exporter/0"} 703
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-operator/0",quantile="0.01"} 0.000328865
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-operator/0",quantile="0.05"} 0.000331039
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-operator/0",quantile="0.5"} 0.00039012
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-operator/0",quantile="0.9"} 0.000481898
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-operator/0",quantile="0.99"} 0.001987463
prometheus_target_sync_length_seconds_sum{scrape_job="monitor/prometheus-operator-operator/0"} 0.3736338510000003
prometheus_target_sync_length_seconds_count{scrape_job="monitor/prometheus-operator-operator/0"} 703
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-prometheus/0",quantile="0.01"} 0.000319209
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-prometheus/0",quantile="0.05"} 0.000331405
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-prometheus/0",quantile="0.5"} 0.000386704
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-prometheus/0",quantile="0.9"} 0.000482045
prometheus_target_sync_length_seconds{scrape_job="monitor/prometheus-operator-prometheus/0",quantile="0.99"} 0.002215811
prometheus_target_sync_length_seconds_sum{scrape_job="monitor/prometheus-operator-prometheus/0"} 0.316109397
prometheus_target_sync_length_seconds_count{scrape_job="monitor/prometheus-operator-prometheus/0"} 703
# HELP prometheus_template_text_expansion_failures_total The total number of template text expansion failures.
# TYPE prometheus_template_text_expansion_failures_total counter
prometheus_template_text_expansion_failures_total 0
# HELP prometheus_template_text_expansions_total The total number of template text expansions.
# TYPE prometheus_template_text_expansions_total counter
prometheus_template_text_expansions_total 2561
# HELP prometheus_treecache_watcher_goroutines The current number of watcher goroutines.
# TYPE prometheus_treecache_watcher_goroutines gauge
prometheus_treecache_watcher_goroutines 0
# HELP prometheus_treecache_zookeeper_failures_total The total number of ZooKeeper failures.
# TYPE prometheus_treecache_zookeeper_failures_total counter
prometheus_treecache_zookeeper_failures_total 0
# HELP prometheus_tsdb_blocks_loaded Number of currently loaded data blocks
# TYPE prometheus_tsdb_blocks_loaded gauge
prometheus_tsdb_blocks_loaded 0
# HELP prometheus_tsdb_checkpoint_creations_failed_total Total number of checkpoint creations that failed.
# TYPE prometheus_tsdb_checkpoint_creations_failed_total counter
prometheus_tsdb_checkpoint_creations_failed_total 0
# HELP prometheus_tsdb_checkpoint_creations_total Total number of checkpoint creations attempted.
# TYPE prometheus_tsdb_checkpoint_creations_total counter
prometheus_tsdb_checkpoint_creations_total 0
# HELP prometheus_tsdb_checkpoint_deletions_failed_total Total number of checkpoint deletions that failed.
# TYPE prometheus_tsdb_checkpoint_deletions_failed_total counter
prometheus_tsdb_checkpoint_deletions_failed_total 0
# HELP prometheus_tsdb_checkpoint_deletions_total Total number of checkpoint deletions attempted.
# TYPE prometheus_tsdb_checkpoint_deletions_total counter
prometheus_tsdb_checkpoint_deletions_total 0
# HELP prometheus_tsdb_compaction_chunk_range_seconds Final time range of chunks on their first compaction
# TYPE prometheus_tsdb_compaction_chunk_range_seconds histogram
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="100"} 0
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="400"} 0
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="1600"} 0
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="6400"} 0
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="25600"} 0
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="102400"} 0
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="409600"} 0
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="1.6384e+06"} 0
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="6.5536e+06"} 0
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="2.62144e+07"} 0
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="+Inf"} 0
prometheus_tsdb_compaction_chunk_range_seconds_sum 0
prometheus_tsdb_compaction_chunk_range_seconds_count 0
# HELP prometheus_tsdb_compaction_chunk_samples Final number of samples on their first compaction
# TYPE prometheus_tsdb_compaction_chunk_samples histogram
prometheus_tsdb_compaction_chunk_samples_bucket{le="4"} 0
prometheus_tsdb_compaction_chunk_samples_bucket{le="6"} 0
prometheus_tsdb_compaction_chunk_samples_bucket{le="9"} 0
prometheus_tsdb_compaction_chunk_samples_bucket{le="13.5"} 0
prometheus_tsdb_compaction_chunk_samples_bucket{le="20.25"} 0
prometheus_tsdb_compaction_chunk_samples_bucket{le="30.375"} 0
prometheus_tsdb_compaction_chunk_samples_bucket{le="45.5625"} 0
prometheus_tsdb_compaction_chunk_samples_bucket{le="68.34375"} 0
prometheus_tsdb_compaction_chunk_samples_bucket{le="102.515625"} 0
prometheus_tsdb_compaction_chunk_samples_bucket{le="153.7734375"} 0
prometheus_tsdb_compaction_chunk_samples_bucket{le="230.66015625"} 0
prometheus_tsdb_compaction_chunk_samples_bucket{le="345.990234375"} 0
prometheus_tsdb_compaction_chunk_samples_bucket{le="+Inf"} 0
prometheus_tsdb_compaction_chunk_samples_sum 0
prometheus_tsdb_compaction_chunk_samples_count 0
# HELP prometheus_tsdb_compaction_chunk_size_bytes Final size of chunks on their first compaction
# TYPE prometheus_tsdb_compaction_chunk_size_bytes histogram
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="32"} 0
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="48"} 0
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="72"} 0
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="108"} 0
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="162"} 0
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="243"} 0
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="364.5"} 0
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="546.75"} 0
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="820.125"} 0
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="1230.1875"} 0
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="1845.28125"} 0
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="2767.921875"} 0
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="+Inf"} 0
prometheus_tsdb_compaction_chunk_size_bytes_sum 0
prometheus_tsdb_compaction_chunk_size_bytes_count 0
# HELP prometheus_tsdb_compaction_duration_seconds Duration of compaction runs
# TYPE prometheus_tsdb_compaction_duration_seconds histogram
prometheus_tsdb_compaction_duration_seconds_bucket{le="1"} 0
prometheus_tsdb_compaction_duration_seconds_bucket{le="2"} 0
prometheus_tsdb_compaction_duration_seconds_bucket{le="4"} 0
prometheus_tsdb_compaction_duration_seconds_bucket{le="8"} 0
prometheus_tsdb_compaction_duration_seconds_bucket{le="16"} 0
prometheus_tsdb_compaction_duration_seconds_bucket{le="32"} 0
prometheus_tsdb_compaction_duration_seconds_bucket{le="64"} 0
prometheus_tsdb_compaction_duration_seconds_bucket{le="128"} 0
prometheus_tsdb_compaction_duration_seconds_bucket{le="256"} 0
prometheus_tsdb_compaction_duration_seconds_bucket{le="512"} 0
prometheus_tsdb_compaction_duration_seconds_bucket{le="+Inf"} 0
prometheus_tsdb_compaction_duration_seconds_sum 0
prometheus_tsdb_compaction_duration_seconds_count 0
# HELP prometheus_tsdb_compaction_populating_block Set to 1 when a block is currently being written to the disk.
# TYPE prometheus_tsdb_compaction_populating_block gauge
prometheus_tsdb_compaction_populating_block 0
# HELP prometheus_tsdb_compactions_failed_total Total number of compactions that failed for the partition.
# TYPE prometheus_tsdb_compactions_failed_total counter
prometheus_tsdb_compactions_failed_total 0
# HELP prometheus_tsdb_compactions_total Total number of compactions that were executed for the partition.
# TYPE prometheus_tsdb_compactions_total counter
prometheus_tsdb_compactions_total 0
# HELP prometheus_tsdb_compactions_triggered_total Total number of triggered compactions for the partition.
# TYPE prometheus_tsdb_compactions_triggered_total counter
prometheus_tsdb_compactions_triggered_total 59
# HELP prometheus_tsdb_head_active_appenders Number of currently active appender transactions
# TYPE prometheus_tsdb_head_active_appenders gauge
prometheus_tsdb_head_active_appenders 16
# HELP prometheus_tsdb_head_chunks Total number of chunks in the head block.
# TYPE prometheus_tsdb_head_chunks gauge
prometheus_tsdb_head_chunks 74584
# HELP prometheus_tsdb_head_chunks_created_total Total number of chunks created in the head
# TYPE prometheus_tsdb_head_chunks_created_total counter
prometheus_tsdb_head_chunks_created_total 74584
# HELP prometheus_tsdb_head_chunks_removed_total Total number of chunks removed in the head
# TYPE prometheus_tsdb_head_chunks_removed_total counter
prometheus_tsdb_head_chunks_removed_total 0
# HELP prometheus_tsdb_head_gc_duration_seconds Runtime of garbage collection in the head block.
# TYPE prometheus_tsdb_head_gc_duration_seconds summary
prometheus_tsdb_head_gc_duration_seconds_sum 0
prometheus_tsdb_head_gc_duration_seconds_count 0
# HELP prometheus_tsdb_head_max_time Maximum timestamp of the head block. The unit is decided by the library consumer.
# TYPE prometheus_tsdb_head_max_time gauge
prometheus_tsdb_head_max_time 1.578492735448e+12
# HELP prometheus_tsdb_head_max_time_seconds Maximum timestamp of the head block.
# TYPE prometheus_tsdb_head_max_time_seconds gauge
prometheus_tsdb_head_max_time_seconds 1.578492735448e+09
# HELP prometheus_tsdb_head_min_time Minimum time bound of the head block. The unit is decided by the library consumer.
# TYPE prometheus_tsdb_head_min_time gauge
prometheus_tsdb_head_min_time 1.578489168924e+12
# HELP prometheus_tsdb_head_min_time_seconds Minimum time bound of the head block.
# TYPE prometheus_tsdb_head_min_time_seconds gauge
prometheus_tsdb_head_min_time_seconds 1.578489168924e+09
# HELP prometheus_tsdb_head_samples_appended_total Total number of appended samples.
# TYPE prometheus_tsdb_head_samples_appended_total counter
prometheus_tsdb_head_samples_appended_total 3.793621e+06
# HELP prometheus_tsdb_head_series Total number of series in the head block.
# TYPE prometheus_tsdb_head_series gauge
prometheus_tsdb_head_series 41374
# HELP prometheus_tsdb_head_series_created_total Total number of series created in the head
# TYPE prometheus_tsdb_head_series_created_total counter
prometheus_tsdb_head_series_created_total 41374
# HELP prometheus_tsdb_head_series_not_found_total Total number of requests for series that were not found.
# TYPE prometheus_tsdb_head_series_not_found_total counter
prometheus_tsdb_head_series_not_found_total 0
# HELP prometheus_tsdb_head_series_removed_total Total number of series removed in the head
# TYPE prometheus_tsdb_head_series_removed_total counter
prometheus_tsdb_head_series_removed_total 0
# HELP prometheus_tsdb_head_truncations_failed_total Total number of head truncations that failed.
# TYPE prometheus_tsdb_head_truncations_failed_total counter
prometheus_tsdb_head_truncations_failed_total 0
# HELP prometheus_tsdb_head_truncations_total Total number of head truncations attempted.
# TYPE prometheus_tsdb_head_truncations_total counter
prometheus_tsdb_head_truncations_total 0
# HELP prometheus_tsdb_lowest_timestamp Lowest timestamp value stored in the database. The unit is decided by the library consumer.
# TYPE prometheus_tsdb_lowest_timestamp gauge
prometheus_tsdb_lowest_timestamp 1.578489168924e+12
# HELP prometheus_tsdb_lowest_timestamp_seconds Lowest timestamp value stored in the database.
# TYPE prometheus_tsdb_lowest_timestamp_seconds gauge
prometheus_tsdb_lowest_timestamp_seconds 1.578489168924e+09
# HELP prometheus_tsdb_reloads_failures_total Number of times the database failed to reload block data from disk.
# TYPE prometheus_tsdb_reloads_failures_total counter
prometheus_tsdb_reloads_failures_total 0
# HELP prometheus_tsdb_reloads_total Number of times the database reloaded block data from disk.
# TYPE prometheus_tsdb_reloads_total counter
prometheus_tsdb_reloads_total 1
# HELP prometheus_tsdb_retention_limit_bytes Max number of bytes to be retained in the tsdb blocks, configured 0 means disabled
# TYPE prometheus_tsdb_retention_limit_bytes gauge
prometheus_tsdb_retention_limit_bytes 0
# HELP prometheus_tsdb_size_retentions_total The number of times that blocks were deleted because the maximum number of bytes was exceeded.
# TYPE prometheus_tsdb_size_retentions_total counter
prometheus_tsdb_size_retentions_total 0
# HELP prometheus_tsdb_storage_blocks_bytes The number of bytes that are currently used for local storage by all blocks.
# TYPE prometheus_tsdb_storage_blocks_bytes gauge
prometheus_tsdb_storage_blocks_bytes 0
# HELP prometheus_tsdb_symbol_table_size_bytes Size of symbol table on disk (in bytes)
# TYPE prometheus_tsdb_symbol_table_size_bytes gauge
prometheus_tsdb_symbol_table_size_bytes 0
# HELP prometheus_tsdb_time_retentions_total The number of times that blocks were deleted because the maximum time limit was exceeded.
# TYPE prometheus_tsdb_time_retentions_total counter
prometheus_tsdb_time_retentions_total 0
# HELP prometheus_tsdb_tombstone_cleanup_seconds The time taken to recompact blocks to remove tombstones.
# TYPE prometheus_tsdb_tombstone_cleanup_seconds histogram
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="0.005"} 0
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="0.01"} 0
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="0.025"} 0
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="0.05"} 0
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="0.1"} 0
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="0.25"} 0
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="0.5"} 0
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="1"} 0
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="2.5"} 0
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="5"} 0
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="10"} 0
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="+Inf"} 0
prometheus_tsdb_tombstone_cleanup_seconds_sum 0
prometheus_tsdb_tombstone_cleanup_seconds_count 0
# HELP prometheus_tsdb_vertical_compactions_total Total number of compactions done on overlapping blocks.
# TYPE prometheus_tsdb_vertical_compactions_total counter
prometheus_tsdb_vertical_compactions_total 0
# HELP prometheus_tsdb_wal_completed_pages_total Total number of completed pages.
# TYPE prometheus_tsdb_wal_completed_pages_total counter
prometheus_tsdb_wal_completed_pages_total 1663
# HELP prometheus_tsdb_wal_corruptions_total Total number of WAL corruptions.
# TYPE prometheus_tsdb_wal_corruptions_total counter
prometheus_tsdb_wal_corruptions_total 0
# HELP prometheus_tsdb_wal_fsync_duration_seconds Duration of WAL fsync.
# TYPE prometheus_tsdb_wal_fsync_duration_seconds summary
prometheus_tsdb_wal_fsync_duration_seconds{quantile="0.5"} NaN
prometheus_tsdb_wal_fsync_duration_seconds{quantile="0.9"} NaN
prometheus_tsdb_wal_fsync_duration_seconds{quantile="0.99"} NaN
prometheus_tsdb_wal_fsync_duration_seconds_sum 0
prometheus_tsdb_wal_fsync_duration_seconds_count 0
# HELP prometheus_tsdb_wal_page_flushes_total Total number of page flushes.
# TYPE prometheus_tsdb_wal_page_flushes_total counter
prometheus_tsdb_wal_page_flushes_total 12109
# HELP prometheus_tsdb_wal_segment_current WAL segment index that TSDB is currently writing to.
# TYPE prometheus_tsdb_wal_segment_current gauge
prometheus_tsdb_wal_segment_current 1
# HELP prometheus_tsdb_wal_truncate_duration_seconds Duration of WAL truncation.
# TYPE prometheus_tsdb_wal_truncate_duration_seconds summary
prometheus_tsdb_wal_truncate_duration_seconds_sum 0
prometheus_tsdb_wal_truncate_duration_seconds_count 0
# HELP prometheus_tsdb_wal_truncations_failed_total Total number of WAL truncations that failed.
# TYPE prometheus_tsdb_wal_truncations_failed_total counter
prometheus_tsdb_wal_truncations_failed_total 0
# HELP prometheus_tsdb_wal_truncations_total Total number of WAL truncations attempted.
# TYPE prometheus_tsdb_wal_truncations_total counter
prometheus_tsdb_wal_truncations_total 0
# HELP promhttp_metric_handler_requests_in_flight Current number of scrapes being served.
# TYPE promhttp_metric_handler_requests_in_flight gauge
promhttp_metric_handler_requests_in_flight 1
# HELP promhttp_metric_handler_requests_total Total number of scrapes by HTTP status code.
# TYPE promhttp_metric_handler_requests_total counter
promhttp_metric_handler_requests_total{code="200"} 126
promhttp_metric_handler_requests_total{code="500"} 0
promhttp_metric_handler_requests_total{code="503"} 0
